{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2J6ifeEm_IP5",
    "outputId": "c94528f7-dcf0-454f-e3e1-c1b0dff3a7f0"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJsw2n59eDqo",
    "outputId": "bf3fe54f-78fc-4674-8180-9bd20b1db150"
   },
   "outputs": [],
   "source": [
    "## Install NeMo\n",
    "BRANCH = 'main'\n",
    "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ab6jocGAQXA",
    "outputId": "4a6792a1-16c7-40c0-d8a5-583a074fa3d4"
   },
   "outputs": [],
   "source": [
    "!wget https://www.openslr.org/resources/12/train-clean-100.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ASNGklQCn3Q",
    "outputId": "e1c9d169-7ab6-47b0-e4a6-6bed1015f617"
   },
   "outputs": [],
   "source": [
    "!wget https://www.openslr.org/resources/12/test-clean.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XWfK-FWka7f",
    "outputId": "cacd9ccc-588e-414d-e8f4-7f6851c68264"
   },
   "outputs": [],
   "source": [
    "!wget https://www.openslr.org/resources/12/dev-clean.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDoDlHT4Arbz"
   },
   "outputs": [],
   "source": [
    "!tar xvzf train-clean-100.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqJjIhukkk23",
    "outputId": "62434097-7217-4820-900f-8d81027ab7c2"
   },
   "outputs": [],
   "source": [
    "!tar xvzf dev-clean.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nIISdEXyC66l",
    "outputId": "3912597c-77ee-4129-8d04-077646b19762"
   },
   "outputs": [],
   "source": [
    "!tar xvzf test-clean.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "IWBEV97n_v85"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torchaudio.models import RNNT,Emformer,emformer_rnnt_base,emformer_rnnt_model\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchaudio import functional as audioF\n",
    "from torchaudio import transforms as audioT\n",
    "import torchaudio\n",
    "import Levenshtein as Lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "TtPQXRrUA75M"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from glob import glob\n",
    "#import librosa\n",
    "from tqdm import tqdm\n",
    "#import soundfile as sf\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from parasol import Composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "lXK65W92CyzH"
   },
   "outputs": [],
   "source": [
    "def wer(s1,s2):\n",
    "    b = set(s1.split()+s2.split())\n",
    "    word_map = dict(zip(b,range(len(b))))\n",
    "    print(\"word_map:\",word_map)\n",
    "    w1 = [chr(word_map[w]) for w in s1.split()]\n",
    "    w2 = [chr(word_map[w]) for w in s2.split()]\n",
    "    dev = max(len(s2.split()),1)\n",
    "    score = Lev.distance(\"\".join(w1),\"\".join(w2))/dev\n",
    "    return score\n",
    "\n",
    "def cer(s1,s2):\n",
    "    w1 = s1.replace(\" \",\"\")\n",
    "    w2 = s2.replace(\" \",\"\")\n",
    "    dev = max(len(s2),1)\n",
    "    score = Lev.distance((w1),(w2))/dev\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chosung = (\"ㄱ\", \"ㄲ\", \"ㄴ\", \"ㄷ\", \"ㄸ\", \"ㄹ\", \"ㅁ\", \"ㅂ\", \"ㅃ\", \"ㅅ\", \"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅉ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\")\n",
    "\n",
    "jungsung = (\"ㅏ\", \"ㅐ\", \"ㅑ\", \"ㅒ\", \"ㅓ\", \"ㅔ\", \"ㅕ\", \"ㅖ\", \"ㅗ\", \"ㅘ\", \"ㅙ\", \"ㅚ\", \"ㅛ\", \"ㅜ\", \"ㅝ\", \"ㅞ\", \"ㅟ\", \"ㅠ\", \"ㅡ\", \"ㅢ\", \"ㅣ\")\n",
    "\n",
    "jongsung = (\"\", \"ㄱ\", \"ㄲ\", \"ㄳ\", \"ㄴ\", \"ㄵ\", \"ㄶ\", \"ㄷ\", \"ㄹ\", \"ㄺ\", \"ㄻ\", \"ㄼ\", \"ㄽ\", \"ㄾ\", \"ㄿ\", \"ㅀ\", \"ㅁ\", \"ㅂ\", \"ㅄ\", \"ㅅ\", \"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\")\n",
    "\n",
    "ENGS = tuple([chr(ord(\"A\")+i) for i in range(26)])\n",
    "\n",
    "special_chars = tuple(list(\" #$!?@~^&*()[]'~.\\\"`_:\"))\n",
    "\n",
    "import re\n",
    "\n",
    "def replaceBracket(sentence):\n",
    "    rst = re.sub( \"(\\(((\\S|\\s)*)(\\)_))\",\"\",sentence)\n",
    "    rst = re.sub( \"(\\(((\\S|\\s)*)(\\)))\",\"\",rst)\n",
    "    return rst\n",
    "\n",
    "def getHangeulIndex(one_character):\n",
    "    \n",
    "    for i,comp in enumerate(chosung+jungsung+jongsung+ENGS+special_chars):\n",
    "        \n",
    "        if(one_character.upper()==comp):\n",
    "            result = i\n",
    "            if(i<len(chosung)):\n",
    "                result = i\n",
    "            elif(i<len(chosung)+len(jungsung)):\n",
    "                result = i+len(chosung)\n",
    "            elif(i<len(chosung)+len(jungsung)+len(jongsung)):\n",
    "                result = i+len(chosung)+len(jungsung)\n",
    "            return i+5\n",
    "    return 4\n",
    "def convertString2HangeulIndex(text):\n",
    "    result = []\n",
    "    for character in text:\n",
    "        result.append(getHangeulIndex(character))\n",
    "    return result\n",
    "\n",
    "def isHangeul(one_character):\n",
    "    return 0xAC00 <= ord(one_character[:1]) <= 0xD7A3\n",
    "\n",
    "def hangeulExplode(one_hangeul):\n",
    "    a = one_hangeul[:1]\n",
    "    if isHangeul(a) != True:\n",
    "        return False\n",
    "    b = ord(a) - 0xAC00\n",
    "    cho = b // (21*28)\n",
    "    jung = b % (21*28) // 28\n",
    "    jong = b % 28\n",
    "    if jong == 0:\n",
    "        return (chosung[cho], jungsung[jung],-1)\n",
    "    else:\n",
    "        return (chosung[cho], jungsung[jung], jongsung[jong],-1)\n",
    "\n",
    "def hangeulJoin(inputlist):\n",
    "    result = \"\"\n",
    "    cho, jung, jong = 0, 0, 0\n",
    "    inputlist.insert(0, \"\")\n",
    "    while len(inputlist) > 1:\n",
    "        if inputlist[-1] in jongsung:\n",
    "            if inputlist[-2] in jungsung:\n",
    "                jong = jongsung.index(inputlist.pop())\n",
    "            \n",
    "            else:\n",
    "                result += inputlist.pop()\n",
    "        elif inputlist[-1] in jungsung:\n",
    "            if inputlist[-2] in chosung:\n",
    "                jung = jungsung.index(inputlist.pop())\n",
    "                cho = chosung.index(inputlist.pop())\n",
    "                result += chr(0xAC00 + ((cho*21)+jung)*28+jong)\n",
    "                cho, jung, jong = 0, 0, 0\n",
    "            else:\n",
    "                result += inputlist.pop()\n",
    "\n",
    "        else:\n",
    "            result += inputlist.pop()\n",
    "    else:\n",
    "        return result[::-1]\n",
    "\n",
    "def pureosseugi(inputtext):\n",
    "    result = \"\"\n",
    "    for i in inputtext:\n",
    "        if isHangeul(i) == True:\n",
    "            for j in hangeulExplode(i):\n",
    "                result += j\n",
    "        else:\n",
    "            result += i\n",
    "    \n",
    "    return result\n",
    "\n",
    "def bracket_filter(sentence):\n",
    "    new_sentence = str()\n",
    "    flag = False\n",
    "    \n",
    "    for ch in sentence:\n",
    "        if ch == '(' and flag == False: \n",
    "            flag = True\n",
    "            continue\n",
    "        if ch == '(' and flag == True:\n",
    "            flag = False\n",
    "            continue\n",
    "        if ch != ')' and flag == False:\n",
    "            new_sentence += ch\n",
    "    return new_sentence\n",
    "\n",
    "def special_filter(sentence):\n",
    "    SENTENCE_MARK = ['?', '!']\n",
    "    NOISE = ['o', 'n', 'u', 'b', 'l']\n",
    "    EXCEPT = ['/', '+', '*', '-', '@', '$', '^', '&', '[', ']', '=', ':', ';', '.', ',']\n",
    "    \n",
    "    new_sentence = str()\n",
    "    for idx, ch in enumerate(sentence):\n",
    "        if ch not in SENTENCE_MARK:\n",
    "            # o/, n/ 등 처리\n",
    "            if idx + 1 < len(sentence) and ch in NOISE and sentence[idx+1] == '/': \n",
    "                continue \n",
    "\n",
    "        if ch == '#': \n",
    "            new_sentence += '샾'\n",
    "\n",
    "        elif ch not in EXCEPT: \n",
    "            new_sentence += ch\n",
    "\n",
    "    pattern = re.compile(r'\\s\\s+')\n",
    "    new_sentence = re.sub(pattern, ' ', new_sentence.strip())\n",
    "    return new_sentence\n",
    "\n",
    "def sentence_filter(raw_sentence):\n",
    "    return special_filter(bracket_filter(raw_sentence))\n",
    "\n",
    "def bracketContentFilter(text):\n",
    "    #괄호가 페어를 이루고 있다는 전제로 짜여진 함수\n",
    "    def contentExtractor(tmp_value):\n",
    "        if(tmp_value.find(\":\")):\n",
    "            tmp2 = tmp_value.split(\":\",1)\n",
    "            return tmp2[-1]\n",
    "        else:\n",
    "            return tmp_value\n",
    "    isBracket = False\n",
    "    result = \"\"\n",
    "    tmp = \"\"\n",
    "    for c in text:\n",
    "        if(c==\"(\"):\n",
    "            isBracket = True\n",
    "        elif(c==\")\"):\n",
    "            result += contentExtractor(tmp)\n",
    "            isBracket = False\n",
    "            tmp = \"\"\n",
    "        elif(isBracket==True):\n",
    "            tmp += c\n",
    "        else:\n",
    "            result += c\n",
    "    return result\n",
    "\n",
    "def text2vector(inputtext):\n",
    "    def chosung2index(v):\n",
    "        for i,cho in enumerate(chosung):\n",
    "            if(v==cho):\n",
    "                return i\n",
    "        return -1\n",
    "    def jungsung2index(v):\n",
    "        for i,jung in enumerate(jungsung):\n",
    "            if(jung==v):\n",
    "                return i+len(chosung)\n",
    "        return -1\n",
    "    def jongsung2index(v):\n",
    "        for i,jong in enumerate(jongsung):\n",
    "            if(jong==v):\n",
    "                return i+len(chosung)+len(jungsung)\n",
    "        return -1\n",
    "    chojongsung = list(set(chosung+jungsung))\n",
    "    def chojongsung2index(v):\n",
    "        for i,jong in enumerate(chojongsung):\n",
    "            if(jong==v):\n",
    "                return i+len(chosung)+len(jungsung)\n",
    "        return -1\n",
    "    \n",
    "    result = []\n",
    "    etc_chars = list(ENGS+special_chars)\n",
    "    for i in inputtext:\n",
    "        if isHangeul(i) == True:\n",
    "            hexp = hangeulExplode(i)\n",
    "            hexp_len = len(hexp)\n",
    "            if(hexp_len==4):\n",
    "                cho,jung,jong,last = hexp\n",
    "                choidx = chosung2index(cho)\n",
    "                if(choidx!=-1):\n",
    "                    result.append(choidx)\n",
    "                jungidx = jungsung2index(jung)\n",
    "                if(jungidx!=-1):\n",
    "                    result.append(jungidx)\n",
    "                jongidx= jongsung2index(jong)\n",
    "                if(jongidx!=-1):\n",
    "                    result.append(jongidx)\n",
    "                \n",
    "            else:\n",
    "                cho,jung,last = hexp\n",
    "                choidx = chosung2index(cho)\n",
    "                if(choidx!=-1):\n",
    "                    result.append(choidx)\n",
    "                jungidx = jungsung2index(jung)\n",
    "                if(jungidx!=-1):\n",
    "                    result.append(jungidx)\n",
    "            #result.append(last)\n",
    "        else:\n",
    "            idx = -1\n",
    "            for k,v in enumerate(etc_chars):\n",
    "                if(v.lower()==i.lower()):\n",
    "                    result.append(k+len(chosung)+len(jungsung)+len(jongsung))\n",
    "            if(idx!=-1):\n",
    "                result.append(idx)\n",
    "    result = [i+4 for i in result]\n",
    "    return result\n",
    "\n",
    "def vector2text(vec):\n",
    "    etc_chars = list(ENGS+special_chars)\n",
    "    result = \"\"\n",
    "    len_cho = len(chosung)\n",
    "    len_jung = len(jungsung)\n",
    "    len_jong = len(jongsung)\n",
    "    len_etcchars = len(etc_chars)\n",
    "    for i,v in enumerate(vec):\n",
    "        if(v < 2 or v==3):\n",
    "            continue\n",
    "        if(v==2):\n",
    "            break\n",
    "        if(v<len_cho+4):#chosung\n",
    "            result+=chosung[v-4]\n",
    "        elif(v<len_cho+len_jung+4):#jungsung\n",
    "            result += jungsung[(v-4-len_cho)]\n",
    "        elif(v<len_cho+len_jung+len_jong+4):#jongsung\n",
    "            result += jongsung[(v-len_cho-len_jung-4)]\n",
    "        elif(v<len_cho+len_jung+len_jong+len_etcchars+4):\n",
    "            result += etc_chars[v-len_cho-len_jung-len_jong-4]\n",
    "    return result\n",
    "\n",
    "def moasseugi(inputtext):\n",
    "    t1 = []\n",
    "    for i in inputtext:\n",
    "        t1.append(i)\n",
    "\n",
    "    return hangeulJoin(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms as audioT\n",
    "import sentencepiece as spm\n",
    "import jamo\n",
    "\n",
    "class DatasetLoader:\n",
    "    def __init__(self,is_train_dataset:bool,batch_size,top_dataset_folder = \"자유대화 음성(일반남녀)\"):\n",
    "        super().__init__()\n",
    "        section_folder = \"Training\"\n",
    "        if(is_train_dataset==False):\n",
    "            section_folder = \"Validation\"\n",
    "        top_folder = os.path.join(top_dataset_folder,section_folder)\n",
    "        tmp_audios = glob(os.path.join(top_folder,\"*\\\\*.wav\"))\n",
    "        audios = []\n",
    "        for aud in tmp_audios:\n",
    "            ffolder = os.path.dirname(aud)\n",
    "            fname = os.path.basename(aud)\n",
    "            fn = Path(fname).stem\n",
    "            trans_path = os.path.join(ffolder,fn+\".json\")\n",
    "            if(os.path.exists(trans_path)==True):\n",
    "                trans = self.__getTranscription(trans_path)\n",
    "                trans = sentence_filter(trans)\n",
    "                trans = replaceBracket(trans)\n",
    "                #print(\"transcript2:\",transcription)\n",
    "                #trans = text2vector(trans)\n",
    "                #trans = replaceBracket(trans)\n",
    "                if(len(trans)>0):\n",
    "                    audios.append(aud)\n",
    "        self.__audios = audios\n",
    "        use_subset = not True\n",
    "        spm_folder= os.path.dirname(top_dataset_folder)\n",
    "        self.sp = spm.SentencePieceProcessor(model_file=\"spm_bpe_4096_second.model\")\n",
    "        if(is_train_dataset==True and use_subset==True):\n",
    "            audio_len = len(audios)\n",
    "            self.__audios = self.__audios[:audio_len//10]\n",
    "        self.__audio_len = len(self.__audios)\n",
    "        self._batch_size = batch_size\n",
    "    def vector2text(self,vec):\n",
    "        return self.sp.DecodeIds(vec)\n",
    "    def __len__(self):\n",
    "        return self.__audio_len//self._batch_size\n",
    "    def __getTranscription(self,fpath):\n",
    "        with open(fpath,\"r\",encoding=\"UTF-8\") as fp:\n",
    "            data = json.load(fp)[\"발화정보\"][\"stt\"]\n",
    "            #data = sentence_filter(data)\n",
    "            #data = jamo.h2j(data)\n",
    "            #data = jamo.j2hcj(data)\n",
    "        return data\n",
    "    def __getRawAudioData(self,fpath,with_pytorch=True):\n",
    "        if(with_pytorch==True):\n",
    "            data,sample_rate = torchaudio.load(fpath)\n",
    "            return data,sample_rate\n",
    "        else:\n",
    "            import librosa\n",
    "            data,sample_rate = librosa.load(fpath)\n",
    "            return data,sample_rate\n",
    "\n",
    "    def __getAudioData(self,fpath,as_raw_data:bool = False,with_pytorch=True):\n",
    "        data,sample_rate = self.__getRawAudioData(fpath,with_pytorch)\n",
    "        if(as_raw_data==False):\n",
    "            if(with_pytorch==True):\n",
    "                resample_rate = 16000\n",
    "                mfcc_transforms = audioT.MelSpectrogram(sample_rate=resample_rate,n_fft=400,n_mels=96,hop_length=160) #MFCC(sample_rate=resample_rate,n_mfcc=96)\n",
    "                \n",
    "                data = torchaudio.functional.resample(data,sample_rate,resample_rate)\n",
    "                data = mfcc_transforms(data)\n",
    "                #data_mean = data.mean(dim=-1).unsqueeze(-1)\n",
    "                #data_std = data.std(dim=-1).unsqueeze(-1)\n",
    "                #data =  (data-data_mean)/(data_std+1e-35)\n",
    "                data = torch.nan_to_num(data)\n",
    "            \n",
    "                data = torch.nn.functional.pad(data,pad=(0,4))\n",
    "                data = data.transpose(1,2)\n",
    "                data = data.squeeze(0)\n",
    "                length = data.size(0)-4\n",
    "\n",
    "            else:\n",
    "                import librosa\n",
    "                data= librosa.feature.mfcc(y=data,sr=sample_rate).T\n",
    "                data = torch.from_numpy(data)\n",
    "                length = data.size(0)\n",
    "        return data,length\n",
    "        \n",
    "        \n",
    "    def shuffleDataset(self):\n",
    "        random.shuffle(self.__audios)\n",
    "    def __getitem__(self,idx):\n",
    "        if(idx>=self.__len__()):\n",
    "            raise StopIteration()\n",
    "        st_idx,ed_idx = idx*self._batch_size,min((idx+1)*self._batch_size,self.__audio_len)\n",
    "        audios = []\n",
    "        audio_lengths = []\n",
    "        raw_transcripts = []\n",
    "        transcripts = []\n",
    "        transcript_length = []\n",
    "        for i in range(st_idx,ed_idx):\n",
    "            fpath = self.__audios[i]\n",
    "            fname = os.path.basename(fpath)\n",
    "            #print(fname)\n",
    "            ffolder = os.path.dirname(fpath)\n",
    "            transcript_fpath = os.path.join(ffolder,Path(fname).stem+\".json\")\n",
    "            transcription = self.__getTranscription(transcript_fpath)\n",
    "            audio_data,data_length = self.__getAudioData(fpath)\n",
    "            audios.append(audio_data)\n",
    "            audio_lengths.append(data_length)\n",
    "            ori_trans = transcription\n",
    "            \n",
    "            transcription = bracketContentFilter(transcription)\n",
    "            \n",
    "            #print(\"transcript:\",transcription)\n",
    "            transcription = sentence_filter(transcription)\n",
    "            \n",
    "            raw_transcripts.append((ori_trans,transcription,fname))\n",
    "            transcription = replaceBracket(transcription)\n",
    "            #print(\"transcript2:\",transcription)\n",
    "            \n",
    "            #transcription = jamo.j2hcj(jamo.h2j(transcription))\n",
    "            \n",
    "            transcription =  [0] + text2vector(transcription) #self.sp.EncodeAsIds(transcription) #[1]+text2vector(transcription)+[2]\n",
    "            #print(\"transcription:\",transcription)\n",
    "            transcripts.append(torch.from_numpy(np.array(transcription)))\n",
    "\n",
    "            transcript_length.append(len(transcription))#temp length\n",
    "        audios = torch.nn.utils.rnn.pad_sequence(audios,batch_first=True)\n",
    "        audio_lengths = np.array(audio_lengths)\n",
    "        transcript_length = np.array(transcript_length)\n",
    "        #transcripts = np.array(transcripts)\n",
    "        return audios,audio_lengths,transcripts,transcript_length#,raw_transcripts\n",
    "        \n",
    "if(__name__==\"__main__\"):\n",
    "    debug_dataset =  False\n",
    "    if(debug_dataset==True):\n",
    "        from parasol import Composer\n",
    "        text_composer = Composer()\n",
    "        dataset_loader = DatasetLoader(is_train_dataset=True,batch_size=1,top_dataset_folder=\"D:\\\\datasets\\\\aihub\\\\남녀자유대화\\\\자유대화 음성(일반남녀)\")\n",
    "        for i, (audios,audio_lengths,transcripts,transcript_length,raw_transcripts) in enumerate(dataset_loader):\n",
    "            #print(\"audios:\",len(audios),\"transcripts:\",len(transcripts))\n",
    "            sample_audio = audios[0]\n",
    "            sample_transcripts = transcripts[0]\n",
    "            #print(sample_audio.shape)\n",
    "            print(\"  \",sample_transcripts)\n",
    "            decode = vector2text(sample_transcripts[1:].cpu().numpy().tolist())#dataset_loader.vector2text(sample_transcripts[1:].cpu().numpy().tolist())\n",
    "            #decoded = jamo.j2hcj(jamo.h2j(decode))\n",
    "            #decoded2 = text_composer.compose(decoded)\n",
    "            print(f\"  => '{decode}'\")\n",
    "\n",
    "            label = raw_transcripts[0]\n",
    "            if(1==1):#label[0].find(\"(\")!=-1):\n",
    "                filtered_label = label[1]\n",
    "                print(str(i).zfill(6),f\"'{label[0]}'\")\n",
    "                print(f\"\\t\\t'{label[1]}'\")\n",
    "                print(f\"\\t\\t\\t{label[2]}\")\n",
    "            if(i>10):\n",
    "                break\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "G1gODZ44E12W",
    "outputId": "0ff02328-5765-45cd-d13c-17c95a5cf07f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29664\\753021411.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtraindataset_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspecs_lengths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtranscripts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtranscript_lengths\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindataset_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "if(__name__==\"__main__\"):\n",
    "    traindataset_loader = DataLoader(15)\n",
    "    from matplotlib import pyplot as plt\n",
    "    index = 0\n",
    "    for specs,specs_lengths,transcripts,transcript_lengths in tqdm(traindataset_loader):\n",
    "        #print(specs.shape,specs_lengths.shape,transcripts.shape,transcript_lengths.shape)\n",
    "        fig, ax = plt.subplots(nrows=2, sharex=True)\n",
    "        mfcc= specs[0].T\n",
    "        print(\"mfcc:\",mfcc.shape)\n",
    "        print(\"\\t\",(mfcc.min(),mfcc.max()))#(np.min(mfcc),np.max(mfcc)))\n",
    "        img = librosa.display.specshow(librosa.power_to_db(mfcc, ref=np.max),\n",
    "                                      x_axis='time', y_axis='mel',fmin=100, fmax=8000,\n",
    "                                      ax=ax[0])\n",
    "        fig.colorbar(img, ax=[ax[0]])\n",
    "        ax[0].set(title='Mel spectrogram')\n",
    "        ax[0].label_outer()\n",
    "        img = librosa.display.specshow(mfcc, x_axis='time', ax=ax[1])\n",
    "        fig.colorbar(img, ax=[ax[1]])\n",
    "        ax[1].set(title='MFCC')\n",
    "        plt.show()\n",
    "        if(index>20):\n",
    "            break\n",
    "        index+=1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TN3wNCdd4x4n"
   },
   "source": [
    "* https://pytorch.org/audio/stable/generated/torchaudio.models.emformer_rnnt_model.html?highlight=rnnt#torchaudio.models.emformer_rnnt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "izU903zX__eY"
   },
   "outputs": [],
   "source": [
    "net = emformer_rnnt_model(\n",
    "        input_dim=96,\n",
    "        encoding_dim=1024,\n",
    "        num_symbols=256,\n",
    "        segment_length=16,\n",
    "        right_context_length=4,\n",
    "        time_reduction_input_dim=128,\n",
    "        time_reduction_stride=4,\n",
    "        transformer_num_heads=8,\n",
    "        transformer_ffn_dim=2048,#1536,\n",
    "        transformer_num_layers=20,\n",
    "        transformer_dropout=0.1,\n",
    "        transformer_activation=\"gelu\",\n",
    "        transformer_left_context_length=30,\n",
    "        transformer_max_memory_size=0,\n",
    "        transformer_weight_init_scale_strategy=\"depthwise\",\n",
    "        transformer_tanh_on_mem=True,\n",
    "        symbol_embedding_dim=512,\n",
    "        num_lstm_layers=3,\n",
    "        lstm_layer_norm=True,\n",
    "        lstm_layer_norm_epsilon=1e-3,\n",
    "        lstm_dropout=0.3,\n",
    "    )\n",
    "device = torch.device(\"cuda:0\" if(torch.cuda.is_available()==True) else \"cpu\")\n",
    "net = net.to(device)\n",
    "#net.device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gLtZLJSx5Esr"
   },
   "source": [
    "* https://pytorch.org/audio/stable/generated/torchaudio.models.RNNTBeamSearch.html?highlight=beamsearch#torchaudio.models.RNNTBeamSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "bKpUW7PTiOR-"
   },
   "outputs": [],
   "source": [
    "def predict(net,dataset):\n",
    "    net.eval()\n",
    "    state = None\n",
    "    infer = torchaudio.models.RNNTBeamSearch(net,blank=0)\n",
    "    print(\"device:\",device)\n",
    "    with torch.no_grad():\n",
    "        for (features,feat_lens,labels,label_lens) in dataset:\n",
    "            feat_lens,label_lens = torch.from_numpy(feat_lens),torch.from_numpy(label_lens)\n",
    "\n",
    "            features = nn.utils.rnn.pad_sequence(features,batch_first=True)\n",
    "            labels = nn.utils.rnn.pad_sequence(labels,batch_first=True)\n",
    "            \n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            feat_lens = feat_lens.to(device)\n",
    "            label_lens = label_lens.to(device)\n",
    "            \n",
    "            output = infer(features.float(),feat_lens,10)\n",
    "            tmp_output = output[0]\n",
    "            \n",
    "            ori_decode = vector2text(labels[0][1:].cpu().numpy().tolist())#dataset.vector2text(labels[0][1:].cpu().numpy().tolist())\n",
    "            decode = vector2text(tmp_output[0][1:])#dataset.vector2text(tmp_output[0][1:])\n",
    "            #decoded = jamo.j2hcj(jamo.h2j(decode))\n",
    "            #decoded2 = text_composer.compose(decoded)\n",
    "            \n",
    "            print(\"-\"*10)\n",
    "            print(\"\\torigin:\",ori_decode)#vector2text(labels[0].cpu().numpy().tolist()))\n",
    "            print(\"\\tresult:\",decode)#vector2text(tmp_output[0]))\n",
    "            print(\"\\toriginal vec:\",labels[0])\n",
    "            #with_visible_tag\n",
    "            print(\"\\traw_output:\",tmp_output[0])\n",
    "            \n",
    "            \"\"\"\n",
    "            ori_string = dataset.token2String(labels.cpu().numpy()[0].tolist())\n",
    "            pred_string = dataset.token2String(output[0][0])\n",
    "            print(\"\\tori string: \",ori_string)\n",
    "            print(\"\\toutput result:\",output[0][0])\n",
    "            print(\"\\topt string: \",pred_string)\n",
    "            ori_string = dataset.token2String(labels.cpu().numpy()[0].tolist(),with_visible_tag=False)\n",
    "            pred_string = dataset.token2String(output[0][0],with_visible_tag=False)\n",
    "            print(f\"\\topt' string: '{pred_string}'\")\n",
    "            print(\"\\twer:\",wer(pred_string,ori_string))\n",
    "            print(\"\\tcer:\",cer(pred_string,ori_string))\n",
    "            \"\"\"\n",
    "            del features,feat_lens,labels,label_lens\n",
    "            torch.cuda.empty_cache()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del features,feat_lens,labels,label_lens\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "cV2gE6cv7bo3"
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.00008\n",
    "optimizer = optim.Adam(net.parameters(),lr=initial_learning_rate)#,rho=0.95,eps=1e-8,weight_decay=0.0)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer,gamma=0.95) #.CosineAnnealingLR(optimizer,T_max=100,eta_min=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "o-AXfLTY_Vg9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.load(\"./rnnt4r2.pth\")\n",
    "net.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset2 = DatasetLoader(is_train_dataset=True,batch_size=1,top_dataset_folder=\"D:\\\\datasets\\\\aihub\\\\남녀자유대화\\\\자유대화 음성(일반남녀)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imscs\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchaudio\\functional\\functional.py:572: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  \"At least one mel filterbank has all zero values. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\torigin: ㄱㅡㄹㅓㄴ ㅅㅔㅁㅇㅣㅈㅣ ㄱㅡ ㅇㅣㅎㅜ ㅊㅓㄴㅎㅘㅇㅇㅣ ㅈㅣㄴㅏㄷㅏㄱㅏ ㄴㅐㄹㅕㄱㅇㅡㄹ ㄷㅡㄷㄱㅗ ㅇㅣㄹㅡㅁㅇㅡㄹ ㄱㅡㅁㅅㅗㄹㅗㄹㅗ ㅂㅏㄲㅝㅆㄷㅐ\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㅇㅙ\n",
      "\toriginal vec: tensor([ 0,  4, 41,  9, 27, 48, 98, 13, 28, 60, 15, 43, 16, 43, 98,  4, 41, 98,\n",
      "        15, 43, 22, 36, 98, 18, 27, 48, 22, 32, 65, 15, 43, 98, 16, 43,  6, 23,\n",
      "         7, 23,  4, 23, 98,  6, 24,  9, 29, 45, 15, 41, 52, 98,  7, 41, 51,  4,\n",
      "        31, 98, 15, 43,  9, 41, 60, 15, 41, 52, 98,  4, 41, 60, 13, 31,  9, 31,\n",
      "         9, 31, 98, 11, 23,  5, 37, 64,  7, 24], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 15, 33]\n",
      "----------\n",
      "\torigin: ㄱㅡㄹㅓㅎㄱㅜㄴㅏ ㄱㅡ ㅅㅐㅇㄱㅏㄱㅇㅡㄹ ㅁㅗㅅ ㅎㅐㅆㅇㅓ\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏ\n",
      "\toriginal vec: tensor([ 0,  4, 41,  9, 27, 71,  4, 36,  6, 23, 98,  4, 41, 98, 13, 24, 65,  4,\n",
      "        23, 45, 15, 41, 52, 98, 10, 31, 63, 98, 22, 24, 64, 15, 27],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23]\n",
      "----------\n",
      "\torigin: ㅋㅓㄷㅏㄹㅏㄴ ㅈㅓㄴㅊㅓㄹㅇㅡㄹ ㅌㅏㄱㅗ ㅇㅓㄷㅣㄹㅗㄴㄱㅏ ㄱㅏㄱㅗ ㅇㅣㅆㄴㅡㄴㄷㅔ ㅊㅏㅇㅂㅏㄲㅇㅡㄹㅗ ㅎㅐㅅㅅㅏㄹㅇㅣ ㄴㅜㄴㅂㅜㅅㅣㄱㅔ ㅂㅜㅅㅓㅈㅣㄷㅓㄹㅏ\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏㅈㅜㅇㅇㅔ\n",
      "\toriginal vec: tensor([ 0, 19, 27,  7, 23,  9, 23, 48, 98, 16, 27, 48, 18, 27, 52, 15, 41, 52,\n",
      "        98, 20, 23,  4, 31, 98, 15, 27,  7, 43,  9, 31, 48,  4, 23, 98,  4, 23,\n",
      "         4, 31, 98, 15, 43, 64,  6, 41, 48,  7, 28, 98, 18, 23, 65, 11, 23, 46,\n",
      "        15, 41,  9, 31, 98, 22, 24, 63, 13, 23, 52, 15, 43, 98,  6, 36, 48, 11,\n",
      "        36, 13, 43,  4, 28, 98, 11, 36, 13, 27, 16, 43,  7, 27,  9, 23],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23, 16, 36, 65, 15, 28]\n",
      "----------\n",
      "\torigin: ㄷㅐㅎㅕㅇ ㄴㅐㅇㅈㅏㅇㅅㅣㄹㅁㅏㄷㅏ ㅅㅚㄱㅗㄱㅣㄱㅏ ㄱㅏㄷㅡㄱㅎㅏㅂㄴㅣㄷㅏ\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏ\n",
      "\toriginal vec: tensor([ 0,  7, 24, 22, 29, 65, 98,  6, 24, 65, 16, 23, 65, 13, 43, 52, 10, 23,\n",
      "         7, 23, 98, 13, 34,  4, 31,  4, 43,  4, 23, 98,  4, 23,  7, 41, 45, 22,\n",
      "        23, 61,  6, 43,  7, 23], device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23]\n",
      "----------\n",
      "\torigin: ㄱㅖㄷㅏㄴ ㅇㅗㄹㅡㄱㅣ ㅇㅢㅇㅚㄹㅗ ㄷㅏㄴㅅㅜㄴㅎㅏㄴㅔ\n",
      "\tresult: ㄱㅡㄹㅐㅅㅓ ㄱㅡ\n",
      "\toriginal vec: tensor([ 0,  4, 30,  7, 23, 48, 98, 15, 31,  9, 41,  4, 43, 98, 15, 42, 15, 34,\n",
      "         9, 31, 98,  7, 23, 48, 13, 36, 48, 22, 23,  6, 28], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 24, 13, 27, 98, 4, 41]\n",
      "----------\n",
      "\torigin: ㄱㅡㄱㅓㄹ ㅈㅜㅁ ㅍㅐㄴㅣㄱㅇㅣㄹㅏㄱㅗ ㅎㅏㄴㄷㅐ\n",
      "\tresult: ㄱㅡㄹㅐㅅㅓ ㄱㅡ\n",
      "\toriginal vec: tensor([ 0,  4, 41,  4, 27, 52, 98, 16, 36, 60, 98, 21, 24,  6, 43, 45, 15, 43,\n",
      "         9, 23,  4, 31, 98, 22, 23, 48,  7, 24], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 24, 13, 27, 98, 4, 41]\n",
      "----------\n",
      "\torigin: ㄱㅡㄹㅓㅎㅈㅣ\n",
      "\tresult: ㄱㅡㄹㅐㅅㅓ\n",
      "\toriginal vec: tensor([ 0,  4, 41,  9, 27, 71, 16, 43], device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 24, 13, 27]\n",
      "----------\n",
      "\torigin: ㅇㅗㄹㅎㅐ ㄱㅘㅇㅣㄹㄷㅗ ㅍㅜㅇㅅㅓㅇㅎㅏㄹ ㄱㅓㅅㅇㅡㄹㅗ ㅇㅖㅅㅏㅇㄷㅚㅂㄴㅣㄷㅏ\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏ\n",
      "\toriginal vec: tensor([ 0, 15, 31, 52, 22, 24, 98,  4, 32, 15, 43, 52,  7, 31, 98, 21, 36, 65,\n",
      "        13, 27, 65, 22, 23, 52, 98,  4, 27, 63, 15, 41,  9, 31, 98, 15, 30, 13,\n",
      "        23, 65,  7, 34, 61,  6, 43,  7, 23], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23]\n",
      "----------\n",
      "\torigin: ㅇㅏㄹㅊㅡㅎㅏㅇㅣㅁㅓㄱㅏ ㅂㅏㄹㅅㅐㅇㅎㅏㄴㅡㄴ ㅇㅣㅇㅠㄴㅡㄴㅇㅛ\n",
      "\tresult: ㄱㅡㄹㅐㅅㅓ\n",
      "\toriginal vec: tensor([ 0, 15, 23, 52, 18, 41, 22, 23, 15, 43, 10, 27,  4, 23, 98, 11, 23, 52,\n",
      "        13, 24, 65, 22, 23,  6, 41, 48, 98, 15, 43, 15, 40,  6, 41, 48, 15, 35],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 24, 13, 27]\n",
      "----------\n",
      "\torigin: ㅂㅏㅂ ㅂㅐ ㄸㅏㄹㅗ ㄷㅣㅈㅓㅌㅡ ㅂㅐ ㄸㅏㄹㅗ ㅁㅗㄹㄹㅏ\n",
      "\tresult: ㄱㅡㄹㅐㅅㅓ ㄱㅡ\n",
      "\toriginal vec: tensor([ 0, 11, 23, 61, 98, 11, 24, 98,  8, 23,  9, 31, 98,  7, 43, 16, 27, 20,\n",
      "        41, 98, 11, 24, 98,  8, 23,  9, 31, 98, 10, 31, 52,  9, 23],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 24, 13, 27, 98, 4, 41]\n",
      "----------\n",
      "\torigin: ㅇㅢㅁㅣ? ㄱㅡㄴㅑㅇ ㅅㅣㄱㅅㅏ ㅎㅜㅇㅔ ㅁㅓㄱㄴㅡㄴ ㅇㅡㅁㅅㅣㄱㅇㅡㄹ ㅁㅏㄹㅎㅏㄴㅡㄴ ㄱㅓ ㅇㅏㄴㅣㅇㅑ?\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏ\n",
      "\toriginal vec: tensor([  0,  15,  42,  10,  43, 102,  98,   4,  41,   6,  25,  65,  98,  13,\n",
      "         43,  45,  13,  23,  98,  22,  36,  15,  28,  98,  10,  27,  45,   6,\n",
      "         41,  48,  98,  15,  41,  60,  13,  43,  45,  15,  41,  52,  98,  10,\n",
      "         23,  52,  22,  23,   6,  41,  48,  98,   4,  27,  98,  15,  23,   6,\n",
      "         43,  15,  25, 102], device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23]\n",
      "----------\n",
      "\torigin: ㅁㅏㅈㅇㅏ ㅎㅐㅇㅚ ㅇㅕㅎㅐㅇ ㄱㅏㅁㅕㄴ ㄱㅡ ㄴㅏㄹㅏㅇㅢ ㄷㅣㅈㅓㅌㅡ ㅁㅓㄱㅇㅓㅂㅗㄴㅡㄴ ㅈㅐㅁㅣㄷㅗ ㅆㅗㄹㅆㅗㄹㅎㅏㄷㅓㄹㅏ\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏ\n",
      "\toriginal vec: tensor([ 0, 10, 23, 66, 15, 23, 98, 22, 24, 15, 34, 98, 15, 29, 22, 24, 65, 98,\n",
      "         4, 23, 10, 29, 48, 98,  4, 41, 98,  6, 23,  9, 23, 15, 42, 98,  7, 43,\n",
      "        16, 27, 20, 41, 98, 10, 27, 45, 15, 27, 11, 31,  6, 41, 48, 98, 16, 24,\n",
      "        10, 43,  7, 31, 98, 14, 31, 52, 14, 31, 52, 22, 23,  7, 27,  9, 23],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23]\n",
      "----------\n",
      "\torigin: ㅇㅔㅋㅡㄹㄹㅔㅇㅓ? ㄱㅡㄱㅓㄴ ㅇㅓㄸㅓㄴ ㄷㅣㅈㅓㅌㅡㅇㅑ?\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏ\n",
      "\toriginal vec: tensor([  0,  15,  28,  19,  41,  52,   9,  28,  15,  27, 102,  98,   4,  41,\n",
      "          4,  27,  48,  98,  15,  27,   8,  27,  48,  98,   7,  43,  16,  27,\n",
      "         20,  41,  15,  25, 102], device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23]\n",
      "----------\n",
      "\torigin: ㅁㅏㄹㅁㅏㄴ ㄷㅡㄹㅇㅓㄷㅗ ㅁㅏㄱ ㅅㅓㄹㄹㅔㄴㄷㅏ\n",
      "\tresult: ㄱㅡㄹㅐㅅㅓ ㄱㅡ\n",
      "\toriginal vec: tensor([ 0, 10, 23, 52, 10, 23, 48, 98,  7, 41, 52, 15, 27,  7, 31, 98, 10, 23,\n",
      "        45, 98, 13, 27, 52,  9, 28, 48,  7, 23], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 24, 13, 27, 98, 4, 41]\n",
      "----------\n",
      "\torigin: ㄴㅏㄴ ㅌㅓㅋㅣㅇㅔㅅㅓ ㅁㅓㄱㅇㅡㄴ ㅌㅓㅋㅣㅅㅟ ㄷㅣㄹㄹㅏㅇㅣㅌㅡㄱㅏ ㄷㅚㄱㅔ ㅇㅣㄴㅅㅏㅇㅈㅓㄱㅇㅣㅇㅓㅆㅇㅓ\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏ\n",
      "\toriginal vec: tensor([ 0,  6, 23, 48, 98, 20, 27, 19, 43, 15, 28, 13, 27, 98, 10, 27, 45, 15,\n",
      "        41, 48, 98, 20, 27, 19, 43, 13, 39, 98,  7, 43, 52,  9, 23, 15, 43, 20,\n",
      "        41,  4, 23, 98,  7, 34,  4, 28, 98, 15, 43, 48, 13, 23, 65, 16, 27, 45,\n",
      "        15, 43, 15, 27, 64, 15, 27], device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23]\n",
      "----------\n",
      "\torigin: ㅅㅓㄹㅌㅏㅇㄱㅘ ㅇㅗㄱㅅㅜㅅㅜ ㅈㅓㄴㅂㅜㄴㅇㅡㄹ ㄱㅣㅂㅗㄴㅇㅡㄹㅗ ㅎㅔㅇㅣㅈㅡㄹㄴㅓㅅ ㅎㅗㄷㅜ ㅍㅣㅅㅡㅌㅏㅊㅣㅇㅗ ㄷㅡㅇㅇㅡㄹ ㄴㅓㅎㅇㅓㅅㅓ ㅁㅏㄴㄷㅡㄴ ㄱㅘㅈㅏㅇㅑ\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏㅈㅜㅇㅇㅔ\n",
      "\toriginal vec: tensor([ 0, 13, 27, 52, 20, 23, 65,  4, 32, 98, 15, 31, 45, 13, 36, 13, 36, 98,\n",
      "        16, 27, 48, 11, 36, 48, 15, 41, 52, 98,  4, 43, 11, 31, 48, 15, 41,  9,\n",
      "        31, 98, 22, 28, 15, 43, 16, 41, 52,  6, 27, 63, 98, 22, 31,  7, 36, 98,\n",
      "        21, 43, 13, 41, 20, 23, 18, 43, 15, 31, 98,  7, 41, 65, 15, 41, 52, 98,\n",
      "         6, 27, 71, 15, 27, 13, 27, 98, 10, 23, 48,  7, 41, 48, 98,  4, 32, 16,\n",
      "        23, 15, 25], device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23, 16, 36, 65, 15, 28]\n",
      "----------\n",
      "\torigin: ㅇㅝㄴㄹㅐㄴㅡㄴ ㅇㅣㄴㄷㅗㄱㅏ ㅇㅗㄹㅣㅈㅣㄴㅓㄹㅇㅣㄹㅏㄴㅡㄴㄷㅔ ㅇㅛㅈㅡㅁㅇㅡㄴ ㅌㅓㅋㅣ ㄷㅣㅈㅓㅌㅡㄹㅗ ㄷㅓ ㅇㅠㅁㅕㅇㅎㅐ\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏ\n",
      "\toriginal vec: tensor([ 0, 15, 37, 48,  9, 24,  6, 41, 48, 98, 15, 43, 48,  7, 31,  4, 23, 98,\n",
      "        15, 31,  9, 43, 16, 43,  6, 27, 52, 15, 43,  9, 23,  6, 41, 48,  7, 28,\n",
      "        98, 15, 35, 16, 41, 60, 15, 41, 48, 98, 20, 27, 19, 43, 98,  7, 43, 16,\n",
      "        27, 20, 41,  9, 31, 98,  7, 27, 98, 15, 40, 10, 29, 65, 22, 24],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23]\n",
      "----------\n",
      "\torigin: ㅈㅓㅇㅇㅠㄱㅁㅕㄴㅊㅔ ㅁㅗㅇㅑㅇㅇㅔ ㅅㅐㄱㅅㅐㄱㄲㅏㄹㅇㅣ ㄴㅓㅁㅜㄴㅓㅁㅜ ㅇㅣㅃㅡㄴㄷㅔ ㅈㅓㅇㅁㅏㄹ ㅇㅓㅁㅊㅓㅇㄴㅏㄱㅔ ㄷㅏㄴㅁㅏㅅㅇㅣ ㄴㅏ\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏ\n",
      "\toriginal vec: tensor([ 0, 16, 27, 65, 15, 40, 45, 10, 29, 48, 18, 28, 98, 10, 31, 15, 25, 65,\n",
      "        15, 28, 98, 13, 24, 45, 13, 24, 45,  5, 23, 52, 15, 43, 98,  6, 27, 10,\n",
      "        36,  6, 27, 10, 36, 98, 15, 43, 12, 41, 48,  7, 28, 98, 16, 27, 65, 10,\n",
      "        23, 52, 98, 15, 27, 60, 18, 27, 65,  6, 23,  4, 28, 98,  7, 23, 48, 10,\n",
      "        23, 63, 15, 43, 98,  6, 23], device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23]\n",
      "----------\n",
      "\torigin: ㅊㅓㅇㅡㅁㅇㅔㄴ ㄷㅏㅇㅎㅘㅇㅅㅡㄹㅓㅂㄱㅣㄷㅗ ㅎㅐㅆㄴㅡㄴㄷㅔ ㅎㅢㅎㅏㄴㅎㅏㄱㅔ ㄸㅗ ㄱㅖㅅㅗㄱ ㅅㅐㅇㄱㅏㄱㄴㅏㄷㅓㄹㅏㄱㅗ\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏ\n",
      "\toriginal vec: tensor([ 0, 18, 27, 15, 41, 60, 15, 28, 48, 98,  7, 23, 65, 22, 32, 65, 13, 41,\n",
      "         9, 27, 61,  4, 43,  7, 31, 98, 22, 24, 64,  6, 41, 48,  7, 28, 98, 22,\n",
      "        42, 22, 23, 48, 22, 23,  4, 28, 98,  8, 31, 98,  4, 30, 13, 31, 45, 98,\n",
      "        13, 24, 65,  4, 23, 45,  6, 23,  7, 27,  9, 23,  4, 31],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\torigin: ㄴㅏㄴ ㅎㅗㅇㅋㅗㅇㅇㅔㅅㅓ ㅇㅔㄱㅡㅌㅏㄹㅡㅌㅡㄹㅡㄹ ㅁㅓㄱㅇㅓㅂㅘㅆㄴㅡㄴㄷㅔ ㅍㅗㄹㅡㅌㅜㄱㅏㄹㅎㅏㄱㅗㄴ ㅈㅗㅁ ㄷㅏㄹㅡㄴㄱㅏ\n",
      "\tresult: ㄱㅡㄴㄷㅔ ㄴㅏ\n",
      "\toriginal vec: tensor([ 0,  6, 23, 48, 98, 22, 31, 65, 19, 31, 65, 15, 28, 13, 27, 98, 15, 28,\n",
      "         4, 41, 20, 23,  9, 41, 20, 41,  9, 41, 52, 98, 10, 27, 45, 15, 27, 11,\n",
      "        32, 64,  6, 41, 48,  7, 28, 98, 21, 31,  9, 41, 20, 36,  4, 23, 52, 22,\n",
      "        23,  4, 31, 48, 98, 16, 31, 60, 98,  7, 23,  9, 41, 48,  4, 23],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 48, 7, 28, 98, 6, 23]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29364\\3415068985.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraindataset2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#testdataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29364\\3063148795.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(net, dataset)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mlabel_lens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_lens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeat_lens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mtmp_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchaudio\\models\\rnnt_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, length, beam_width)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[0menc_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchaudio\\models\\rnnt_decoder.py\u001b[0m in \u001b[0;36m_search\u001b[1;34m(self, enc_out, hypo, beam_width)\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[0mnext_token_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gen_next_token_probs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_hypos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                 \u001b[0mnext_token_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_token_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[0mb_hypos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gen_b_hypos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_hypos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_hypos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_token_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_to_b_hypo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msymbols_current_t\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_max_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchaudio\\models\\rnnt_decoder.py\u001b[0m in \u001b[0;36m_gen_b_hypos\u001b[1;34m(self, b_hypos, a_hypos, next_token_probs, key_to_b_hypo)\u001b[0m\n\u001b[0;32m    157\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_hypo_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogaddexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mappend_blank_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m                 \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mappend_blank_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m             h_b = (\n\u001b[0;32m    161\u001b[0m                 \u001b[0m_get_hypo_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predict(net,traindataset2)#testdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = DatasetLoader(is_train_dataset=True,batch_size=2,top_dataset_folder=\"D:\\\\datasets\\\\aihub\\\\남녀자유대화\\\\자유대화 음성(일반남녀)\")\n",
    "testdataset = DatasetLoader(is_train_dataset=False,batch_size=1,top_dataset_folder=\"D:\\\\datasets\\\\aihub\\\\남녀자유대화\\\\자유대화 음성(일반남녀)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mn7hoFZGAAWT",
    "outputId": "abada6d9-cd1e-4486-a515-b486109ff97c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 1/19965 [00:00<2:56:30,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346.698486328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                           | 101/19965 [00:28<1:47:50,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318.6271667480469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                           | 183/19965 [00:50<1:39:51,  3.30it/s]"
     ]
    }
   ],
   "source": [
    "if(__name__==\"__main__\"):\n",
    "    #initial_learning_rate = 0.0001\n",
    "    #import nemo.collections.asr as nemo_asr\n",
    "\n",
    "    max_num_epoch = 100\n",
    "    #optimizer = optim.Adam(net.parameters(),lr=initial_learning_rate)#,rho=0.95,eps=1e-8,weight_decay=0.0)\n",
    "    criterion = torchaudio.transforms.RNNTLoss(blank=-1,reduction='sum',clamp=1.0)#,clamp=1.0)#,fused_log_softmax=True)#,#,clamp=1.0)#'sum')\n",
    "    #criterion = nemo_asr.losses.rnnt.RNNTLoss(num_classes=0)\n",
    "    #traindataset = DatasetLoader(is_train_dataset=True,batch_size=1,top_dataset_folder=\"D:\\\\datasets\\\\aihub\\\\남녀자유대화\\\\자유대화 음성(일반남녀)\")\n",
    "    #testdataset = DatasetLoader(is_train_dataset=False,batch_size=1,top_dataset_folder=\"D:\\\\datasets\\\\aihub\\\\남녀자유대화\\\\자유대화 음성(일반남녀)\")\n",
    "    #torch.save(net.parameters(),\"rnnt.pth\")\n",
    "    #predict(net,testdataset)\n",
    "    \n",
    "    for epoch in range(max_num_epoch):\n",
    "        index = 0\n",
    "        traindataset.shuffleDataset()\n",
    "        losses = []\n",
    "        net.train()\n",
    "        for (features,feat_lens,labels,label_lens) in tqdm((traindataset)):\n",
    "            feat_lens,label_lens = torch.from_numpy(feat_lens),torch.from_numpy(label_lens)\n",
    "            if(len(features)==0):\n",
    "                continue\n",
    "            features = nn.utils.rnn.pad_sequence(features,batch_first=True)#.unsqueeze(1).transpose(2, 3)\n",
    "            labels = nn.utils.rnn.pad_sequence(labels,batch_first=True)\n",
    "            \n",
    "            \"\"\"\n",
    "            sorted_lens,indices = torch.sort(feat_lens.view(-1),dim=0,descending=True)\n",
    "            features = features[indices]\n",
    "            labels = labels[indices]\n",
    "            feat_lens = sorted_lens\n",
    "            label_lens = label_lens[indices]\n",
    "            \"\"\"\n",
    "            \n",
    "            #features = features.float()\n",
    "            \n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            feat_lens = feat_lens.to(device)\n",
    "            label_lens = label_lens.to(device)\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            joint_outputs,src_length,tgt_length,*_ = net(features.float(),feat_lens,labels,label_lens)\n",
    "            \n",
    "            outputs = joint_outputs#\n",
    "            #outputs = nn.functional.log_softmax(joint_outputs,dim=-1)\n",
    "\n",
    "            #loss = criterion(log_probs=outputs,targets=(labels[...,1:]).int(),input_lengths=(src_length-1).int() ,target_lengths=(label_lens-1).int())\n",
    "            loss = criterion(outputs,(labels[...,1:]).contiguous().int(),(src_length-0).int() ,(label_lens-1).int())\n",
    "\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del features,feat_lens,labels,label_lens\n",
    "            torch.cuda.empty_cache()\n",
    "            losses.append(loss.item())\n",
    "            if(index%20==0 and index>0):\n",
    "                torch.save(net.state_dict(),\"r.pth\")\n",
    "            if(index%100==0):\n",
    "                print(loss.item())\n",
    "            index+=1\n",
    "        print(f\"ep={epoch}] loss= \",np.mean(losses))\n",
    "        #scheduler.step()\n",
    "    torch.save(net.state_dict(),\"rnnt4r2.pth\")\n",
    "    predict(net,testdataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),\"rnnt4r2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "----------\n",
      "\torigin: ㄱㅡㄹㅓㄴ ㅅㅔㅁㅇㅣㅈㅣ ㄱㅡ ㅇㅣㅎㅜ ㅊㅓㄴㅎㅘㅇㅇㅣ ㅈㅣㄴㅏㄷㅏㄱㅏ ㄴㅐㄹㅕㄱㅇㅡㄹ ㄷㅡㄷㄱㅗ ㅇㅣㄹㅡㅁㅇㅡㄹ ㄱㅡㅁㅅㅗㄹㅗㄹㅗ ㅂㅏㄲㅝㅆㄷㅐ\n",
      "\tresult: ㄱㅡㄹㅓㅎㅈㅣ ㅋㅡㄹㅔㅍㅔㄴㅡㄴ ㅇㅝㄴㄹㅐ ㅍㅡㄹㅏㅇㅅㅡ ㄷㅣㅈㅓㅌㅡㅇㅣㄴㄷㅔ ㅇㅛㅈㅡㅁㅇㅡㄴ ㅇㅣㄹㅂㅗㄴ ㅋㅡㄹㅔㅍㅔㄷㅗ ㅇㅠㅁㅕㅇㅎㅏㄷㅓㄹㅏ\n",
      "\toriginal vec: tensor([ 0,  4, 41,  9, 27, 48, 98, 13, 28, 60, 15, 43, 16, 43, 98,  4, 41, 98,\n",
      "        15, 43, 22, 36, 98, 18, 27, 48, 22, 32, 65, 15, 43, 98, 16, 43,  6, 23,\n",
      "         7, 23,  4, 23, 98,  6, 24,  9, 29, 45, 15, 41, 52, 98,  7, 41, 51,  4,\n",
      "        31, 98, 15, 43,  9, 41, 60, 15, 41, 52, 98,  4, 41, 60, 13, 31,  9, 31,\n",
      "         9, 31, 98, 11, 23,  5, 37, 64,  7, 24], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 27, 71, 16, 43, 98, 19, 41, 9, 28, 21, 28, 6, 41, 48, 98, 15, 37, 48, 9, 24, 98, 21, 41, 9, 23, 65, 13, 41, 98, 7, 43, 16, 27, 20, 41, 15, 43, 48, 7, 28, 98, 15, 35, 16, 41, 60, 15, 41, 48, 98, 15, 43, 52, 11, 31, 48, 98, 19, 41, 9, 28, 21, 28, 7, 31, 98, 15, 40, 10, 29, 65, 22, 23, 7, 27, 9, 23]\n",
      "----------\n",
      "\torigin: ㄱㅡㄹㅓㅎㄱㅜㄴㅏ ㄱㅡ ㅅㅐㅇㄱㅏㄱㅇㅡㄹ ㅁㅗㅅ ㅎㅐㅆㅇㅓ\n",
      "\tresult: ㄱㅡㄹㅓㅎㅈㅣ ㅋㅡㄹㅔㅍㅔㄴㅡㄴ ㅇㅝㄴㄹㅐ ㅍㅡㄹㅏㅇㅅㅡ ㄷㅣㅈㅓㅌㅡㅇㅣㄴㄷㅔ ㅇㅛㅈㅡㅁㅇㅡㄴ ㅇㅣㄹㅂㅗㄴ ㅋㅡㄹㅔㅍㅔㄷㅗ ㅇㅠㅁㅕㅇㅎㅏㄷㅓㄹㅏ\n",
      "\toriginal vec: tensor([ 0,  4, 41,  9, 27, 71,  4, 36,  6, 23, 98,  4, 41, 98, 13, 24, 65,  4,\n",
      "        23, 45, 15, 41, 52, 98, 10, 31, 63, 98, 22, 24, 64, 15, 27],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 27, 71, 16, 43, 98, 19, 41, 9, 28, 21, 28, 6, 41, 48, 98, 15, 37, 48, 9, 24, 98, 21, 41, 9, 23, 65, 13, 41, 98, 7, 43, 16, 27, 20, 41, 15, 43, 48, 7, 28, 98, 15, 35, 16, 41, 60, 15, 41, 48, 98, 15, 43, 52, 11, 31, 48, 98, 19, 41, 9, 28, 21, 28, 7, 31, 98, 15, 40, 10, 29, 65, 22, 23, 7, 27, 9, 23]\n",
      "----------\n",
      "\torigin: ㅋㅓㄷㅏㄹㅏㄴ ㅈㅓㄴㅊㅓㄹㅇㅡㄹ ㅌㅏㄱㅗ ㅇㅓㄷㅣㄹㅗㄴㄱㅏ ㄱㅏㄱㅗ ㅇㅣㅆㄴㅡㄴㄷㅔ ㅊㅏㅇㅂㅏㄲㅇㅡㄹㅗ ㅎㅐㅅㅅㅏㄹㅇㅣ ㄴㅜㄴㅂㅜㅅㅣㄱㅔ ㅂㅜㅅㅓㅈㅣㄷㅓㄹㅏ\n",
      "\tresult: ㄱㅡㄹㅓㅎㅈㅣ ㅋㅡㄹㅔㅍㅔㄴㅡㄴ ㅇㅝㄴㄹㅐ ㅍㅡㄹㅏㅇㅅㅡ ㄷㅣㅈㅓㅌㅡㅇㅣㄴㄷㅔ ㅇㅛㅈㅡㅁㅇㅡㄴ ㅇㅣㄹㅂㅗㄴ ㅋㅡㄹㅔㅍㅔㄷㅗ ㅇㅠㅁㅕㅇㅎㅏㄷㅓㄹㅏ\n",
      "\toriginal vec: tensor([ 0, 19, 27,  7, 23,  9, 23, 48, 98, 16, 27, 48, 18, 27, 52, 15, 41, 52,\n",
      "        98, 20, 23,  4, 31, 98, 15, 27,  7, 43,  9, 31, 48,  4, 23, 98,  4, 23,\n",
      "         4, 31, 98, 15, 43, 64,  6, 41, 48,  7, 28, 98, 18, 23, 65, 11, 23, 46,\n",
      "        15, 41,  9, 31, 98, 22, 24, 63, 13, 23, 52, 15, 43, 98,  6, 36, 48, 11,\n",
      "        36, 13, 43,  4, 28, 98, 11, 36, 13, 27, 16, 43,  7, 27,  9, 23],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 27, 71, 16, 43, 98, 19, 41, 9, 28, 21, 28, 6, 41, 48, 98, 15, 37, 48, 9, 24, 98, 21, 41, 9, 23, 65, 13, 41, 98, 7, 43, 16, 27, 20, 41, 15, 43, 48, 7, 28, 98, 15, 35, 16, 41, 60, 15, 41, 48, 98, 15, 43, 52, 11, 31, 48, 98, 19, 41, 9, 28, 21, 28, 7, 31, 98, 15, 40, 10, 29, 65, 22, 23, 7, 27, 9, 23]\n",
      "----------\n",
      "\torigin: ㄷㅐㅎㅕㅇ ㄴㅐㅇㅈㅏㅇㅅㅣㄹㅁㅏㄷㅏ ㅅㅚㄱㅗㄱㅣㄱㅏ ㄱㅏㄷㅡㄱㅎㅏㅂㄴㅣㄷㅏ\n",
      "\tresult: ㄱㅡㄹㅓㅎㅈㅣ ㅋㅡㄹㅔㅍㅔㄴㅡㄴ ㅇㅝㄴㄹㅐ ㅍㅡㄹㅏㅇㅅㅡ ㄷㅣㅈㅓㅌㅡㅇㅣㄴㄷㅔ ㅇㅛㅈㅡㅁㅇㅡㄴ ㅇㅣㄹㅂㅗㄴ ㅋㅡㄹㅔㅍㅔㄷㅗ ㅇㅠㅁㅕㅇㅎㅏㄷㅓㄹㅏ\n",
      "\toriginal vec: tensor([ 0,  7, 24, 22, 29, 65, 98,  6, 24, 65, 16, 23, 65, 13, 43, 52, 10, 23,\n",
      "         7, 23, 98, 13, 34,  4, 31,  4, 43,  4, 23, 98,  4, 23,  7, 41, 45, 22,\n",
      "        23, 61,  6, 43,  7, 23], device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 27, 71, 16, 43, 98, 19, 41, 9, 28, 21, 28, 6, 41, 48, 98, 15, 37, 48, 9, 24, 98, 21, 41, 9, 23, 65, 13, 41, 98, 7, 43, 16, 27, 20, 41, 15, 43, 48, 7, 28, 98, 15, 35, 16, 41, 60, 15, 41, 48, 98, 15, 43, 52, 11, 31, 48, 98, 19, 41, 9, 28, 21, 28, 7, 31, 98, 15, 40, 10, 29, 65, 22, 23, 7, 27, 9, 23]\n",
      "----------\n",
      "\torigin: ㄱㅖㄷㅏㄴ ㅇㅗㄹㅡㄱㅣ ㅇㅢㅇㅚㄹㅗ ㄷㅏㄴㅅㅜㄴㅎㅏㄴㅔ\n",
      "\tresult: ㄱㅡㄹㅓㅎㅈㅣ ㅋㅡㄹㅔㅍㅔㄴㅡㄴ ㅇㅝㄴㄹㅐ ㅍㅡㄹㅏㅇㅅㅡ ㄷㅣㅈㅓㅌㅡㅇㅣㄴㄷㅔ ㅇㅛㅈㅡㅁㅇㅡㄴ ㅇㅣㄹㅂㅗㄴ ㅋㅡㄹㅔㅍㅔㄷㅗ ㅇㅠㅁㅕㅇㅎㅏㄷㅓㄹㅏ\n",
      "\toriginal vec: tensor([ 0,  4, 30,  7, 23, 48, 98, 15, 31,  9, 41,  4, 43, 98, 15, 42, 15, 34,\n",
      "         9, 31, 98,  7, 23, 48, 13, 36, 48, 22, 23,  6, 28], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 27, 71, 16, 43, 98, 19, 41, 9, 28, 21, 28, 6, 41, 48, 98, 15, 37, 48, 9, 24, 98, 21, 41, 9, 23, 65, 13, 41, 98, 7, 43, 16, 27, 20, 41, 15, 43, 48, 7, 28, 98, 15, 35, 16, 41, 60, 15, 41, 48, 98, 15, 43, 52, 11, 31, 48, 98, 19, 41, 9, 28, 21, 28, 7, 31, 98, 15, 40, 10, 29, 65, 22, 23, 7, 27, 9, 23]\n",
      "----------\n",
      "\torigin: ㄱㅡㄱㅓㄹ ㅈㅜㅁ ㅍㅐㄴㅣㄱㅇㅣㄹㅏㄱㅗ ㅎㅏㄴㄷㅐ\n",
      "\tresult: ㄱㅡㄹㅓㅎㅈㅣ ㅋㅡㄹㅔㅍㅔㄴㅡㄴ ㅇㅝㄴㄹㅐ ㅍㅡㄹㅏㅇㅅㅡ ㄷㅣㅈㅓㅌㅡㅇㅣㄴㄷㅔ ㅇㅛㅈㅡㅁㅇㅡㄴ ㅇㅣㄹㅂㅗㄴ ㅋㅡㄹㅔㅍㅔㄷㅗ ㅇㅠㅁㅕㅇㅎㅏㄷㅓㄹㅏ\n",
      "\toriginal vec: tensor([ 0,  4, 41,  4, 27, 52, 98, 16, 36, 60, 98, 21, 24,  6, 43, 45, 15, 43,\n",
      "         9, 23,  4, 31, 98, 22, 23, 48,  7, 24], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 27, 71, 16, 43, 98, 19, 41, 9, 28, 21, 28, 6, 41, 48, 98, 15, 37, 48, 9, 24, 98, 21, 41, 9, 23, 65, 13, 41, 98, 7, 43, 16, 27, 20, 41, 15, 43, 48, 7, 28, 98, 15, 35, 16, 41, 60, 15, 41, 48, 98, 15, 43, 52, 11, 31, 48, 98, 19, 41, 9, 28, 21, 28, 7, 31, 98, 15, 40, 10, 29, 65, 22, 23, 7, 27, 9, 23]\n",
      "----------\n",
      "\torigin: ㄱㅡㄹㅓㅎㅈㅣ\n",
      "\tresult: ㄱㅡㄹㅓㅎㅈㅣ ㅋㅡㄹㅔㅍㅔㄴㅡㄴ ㅇㅝㄴㄹㅐ ㅍㅡㄹㅏㅇㅅㅡ ㄷㅣㅈㅓㅌㅡㅇㅣㄴㄷㅔ ㅇㅛㅈㅡㅁㅇㅡㄴ ㅇㅣㄹㅂㅗㄴ ㅋㅡㄹㅔㅍㅔㄷㅗ ㅇㅠㅁㅕㅇㅎㅏㄷㅓㄹㅏ\n",
      "\toriginal vec: tensor([ 0,  4, 41,  9, 27, 71, 16, 43], device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 27, 71, 16, 43, 98, 19, 41, 9, 28, 21, 28, 6, 41, 48, 98, 15, 37, 48, 9, 24, 98, 21, 41, 9, 23, 65, 13, 41, 98, 7, 43, 16, 27, 20, 41, 15, 43, 48, 7, 28, 98, 15, 35, 16, 41, 60, 15, 41, 48, 98, 15, 43, 52, 11, 31, 48, 98, 19, 41, 9, 28, 21, 28, 7, 31, 98, 15, 40, 10, 29, 65, 22, 23, 7, 27, 9, 23]\n",
      "----------\n",
      "\torigin: ㅇㅗㄹㅎㅐ ㄱㅘㅇㅣㄹㄷㅗ ㅍㅜㅇㅅㅓㅇㅎㅏㄹ ㄱㅓㅅㅇㅡㄹㅗ ㅇㅖㅅㅏㅇㄷㅚㅂㄴㅣㄷㅏ\n",
      "\tresult: ㄱㅡㄹㅓㅎㅈㅣ ㅋㅡㄹㅔㅍㅔㄴㅡㄴ ㅇㅝㄴㄹㅐ ㅍㅡㄹㅏㅇㅅㅡ ㄷㅣㅈㅓㅌㅡㅇㅣㄴㄷㅔ ㅇㅛㅈㅡㅁㅇㅡㄴ ㅇㅣㄹㅂㅗㄴ ㅋㅡㄹㅔㅍㅔㄷㅗ ㅇㅠㅁㅕㅇㅎㅏㄷㅓㄹㅏ\n",
      "\toriginal vec: tensor([ 0, 15, 31, 52, 22, 24, 98,  4, 32, 15, 43, 52,  7, 31, 98, 21, 36, 65,\n",
      "        13, 27, 65, 22, 23, 52, 98,  4, 27, 63, 15, 41,  9, 31, 98, 15, 30, 13,\n",
      "        23, 65,  7, 34, 61,  6, 43,  7, 23], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 27, 71, 16, 43, 98, 19, 41, 9, 28, 21, 28, 6, 41, 48, 98, 15, 37, 48, 9, 24, 98, 21, 41, 9, 23, 65, 13, 41, 98, 7, 43, 16, 27, 20, 41, 15, 43, 48, 7, 28, 98, 15, 35, 16, 41, 60, 15, 41, 48, 98, 15, 43, 52, 11, 31, 48, 98, 19, 41, 9, 28, 21, 28, 7, 31, 98, 15, 40, 10, 29, 65, 22, 23, 7, 27, 9, 23]\n",
      "----------\n",
      "\torigin: ㅇㅏㄹㅊㅡㅎㅏㅇㅣㅁㅓㄱㅏ ㅂㅏㄹㅅㅐㅇㅎㅏㄴㅡㄴ ㅇㅣㅇㅠㄴㅡㄴㅇㅛ\n",
      "\tresult: ㄱㅡㄹㅓㅎㅈㅣ ㅋㅡㄹㅔㅍㅔㄴㅡㄴ ㅇㅝㄴㄹㅐ ㅍㅡㄹㅏㅇㅅㅡ ㄷㅣㅈㅓㅌㅡㅇㅣㄴㄷㅔ ㅇㅛㅈㅡㅁㅇㅡㄴ ㅇㅣㄹㅂㅗㄴ ㅋㅡㄹㅔㅍㅔㄷㅗ ㅇㅠㅁㅕㅇㅎㅏㄷㅓㄹㅏ\n",
      "\toriginal vec: tensor([ 0, 15, 23, 52, 18, 41, 22, 23, 15, 43, 10, 27,  4, 23, 98, 11, 23, 52,\n",
      "        13, 24, 65, 22, 23,  6, 41, 48, 98, 15, 43, 15, 40,  6, 41, 48, 15, 35],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "\traw_output: [0, 4, 41, 9, 27, 71, 16, 43, 98, 19, 41, 9, 28, 21, 28, 6, 41, 48, 98, 15, 37, 48, 9, 24, 98, 21, 41, 9, 23, 65, 13, 41, 98, 7, 43, 16, 27, 20, 41, 15, 43, 48, 7, 28, 98, 15, 35, 16, 41, 60, 15, 41, 48, 98, 15, 43, 52, 11, 31, 48, 98, 19, 41, 9, 28, 21, 28, 7, 31, 98, 15, 40, 10, 29, 65, 22, 23, 7, 27, 9, 23]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29664\\827563434.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraindataset2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29664\\3063148795.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(net, dataset)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mlabel_lens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_lens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeat_lens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mtmp_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchaudio\\models\\rnnt_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, length, beam_width)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[0menc_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchaudio\\models\\rnnt_decoder.py\u001b[0m in \u001b[0;36m_search\u001b[1;34m(self, enc_out, hypo, beam_width)\u001b[0m\n\u001b[0;32m    259\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                     \u001b[0mbeam_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m                     \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m                 )\n\u001b[0;32m    263\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0ma_hypos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchaudio\\models\\rnnt_decoder.py\u001b[0m in \u001b[0;36m_gen_a_hypos\u001b[1;34m(self, a_hypos, b_hypos, next_token_probs, t, beam_width, device)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbase_hypos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mnew_hypos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gen_new_hypos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_hypos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mnew_hypos\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mHypothesis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchaudio\\models\\rnnt_decoder.py\u001b[0m in \u001b[0;36m_gen_new_hypos\u001b[1;34m(self, base_hypos, tokens, scores, t, device)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0mtgt_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_hypos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         )\n\u001b[0;32m    224\u001b[0m         \u001b[0mnew_hypos\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mHypothesis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchaudio\\models\\rnnt.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, targets, target_lengths, state)\u001b[0m\n\u001b[0;32m    641\u001b[0m                     \u001b[0mrepresenting\u001b[0m \u001b[0minternal\u001b[0m \u001b[0mstate\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \"\"\"\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchaudio\\models\\rnnt.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, lengths, state)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mstate_out\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m             \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm_state_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m             \u001b[0mlstm_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0mstate_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_state_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torchaudio\\models\\rnnt.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, state)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgates\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgated_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mgates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp2g\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mgates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[0minput_gate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforget_gate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell_gate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_gate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0minput_gate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_gate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\normalization.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         return F.layer_norm(\n\u001b[1;32m--> 191\u001b[1;33m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2513\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2514\u001b[0m         )\n\u001b[1;32m-> 2515\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predict(net,traindataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
